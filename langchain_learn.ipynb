{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3550528",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'your api key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3f74b",
   "metadata": {},
   "source": [
    "# 文档读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "pdf_path = 'path/to/大模型基础 完整版.pdf'\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "pdf_pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0782ee9",
   "metadata": {},
   "source": [
    "# 文档分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf815c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：652\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap = 50)\n",
    "split_docs = text_splitter.split_documents(pdf_pages)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90999b5e",
   "metadata": {},
   "source": [
    "# 存入向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "embedding = ZhipuAIEmbeddings()\n",
    "persist_directory = 'path/to/myAgent/mydb'\n",
    "vectordb = Chroma.from_documents(\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory,\n",
    "    documents=split_docs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae25e9",
   "metadata": {},
   "source": [
    "# 读取数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafe4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1d334",
   "metadata": {},
   "source": [
    "# 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28676c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuaiLLM\n",
    "zhipuai_model = ZhipuaiLLM(model_name=\"glm-4-plus\", temperature=0.1, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f759e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好👋！我是人工智能助手智谱清言（ChatGLM），很高兴见到你，欢迎问我任何问题。', additional_kwargs={}, response_metadata={'time_in_seconds': 0.955}, id='run-7d11b76e-ee6e-47c5-b066-a01de92cd409-0', usage_metadata={'input_tokens': 6, 'output_tokens': 28, 'total_tokens': 34})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipuai_model.invoke('你好')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e339402",
   "metadata": {},
   "source": [
    "# 构建检索问答链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3cdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。请你在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {input}\n",
    "\"\"\"\n",
    "\n",
    "retriveal_chain = vectordb.as_retriever()\n",
    "\n",
    "prompt = PromptTemplate(template=template)\n",
    "qa_chain = (\n",
    "    RunnableParallel({'context':retriveal_chain, 'input':RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | zhipuai_model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dc3361a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompt工程是一种专注于编写输入指令（Prompt）的技术，用于指导生成式人工智能模型执行特定任务，而无需进行繁琐的微调。它通过精心设计的Prompt引导大模型直接适应下游任务，提高模型性能和效率。谢谢你的提问！'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('什么是prompt工程？')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0de6e",
   "metadata": {},
   "source": [
    "# 带历史记忆的多轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0a8765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bob! How can I help you today, Bob?', additional_kwargs={}, response_metadata={'time_in_seconds': 0.81}, id='run-2aee8292-91dd-4a1e-97e4-3b9687a287dd-0', usage_metadata={'input_tokens': 29, 'output_tokens': 16, 'total_tokens': 45})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "# 传入历史记录，重新让模型计算\n",
    "zhipuai_model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b28c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加链\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | zhipuai_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19902eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# 存储历史记忆\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738cd849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Jim! How can I assist you today? If you have any questions or need help with something, feel free to let me know!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc5\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Jim\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff25b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Jim! How can I help you today, Jim?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a67186",
   "metadata": {},
   "source": [
    "# 多个输入的多轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e46006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | zhipuai_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772ee455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定那个key是输入\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"abc11\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e3e487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola, Todd! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5b30264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tu nombre es Todd. ¿Hay algo más en lo que te pueda ayudar?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb9792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "789798be",
   "metadata": {},
   "source": [
    "# 检索+多轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "from operator import itemgetter\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 构建检索器\n",
    "persist_directory = 'path/to/myAgent/mydb'\n",
    "vectordb = Chroma(\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    # 将检索到的文档拼成字符串，便于塞入 {context}\n",
    "    return \"\\n\\n\".join(f\"[{i+1}] {d.page_content}\" for i, d in enumerate(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fa6af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 历史记忆\n",
    "session_store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return session_store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e5aea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是资深推理系统工程师。请综合【知识库】与对话历史，给出准确、简洁、条理清晰的回答。\\n【知识库】\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),   # 关键：用于注入历史消息\n",
    "    (\"human\", \"当前问题：{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f41a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag\n",
    "base_rag_chain = (\n",
    "    {\n",
    "        # 仅把用户 query 传给检索器，然后把文档格式化为字符串\n",
    "        \"context\": itemgetter(\"input\") | retriever | format_docs,\n",
    "        # 提示模板里需要 {input}\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "        # 一定要把 history 这个键继续向下传，供 MessagesPlaceholder 使用\n",
    "        \"history\": itemgetter(\"history\"),\n",
    "    }\n",
    "    | contextual_prompt\n",
    "    | zhipuai_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba0c29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 历史记忆\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    base_rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",     # 指明“用户输入”的键\n",
    "    history_messages_key=\"history\", # 必须与 MessagesPlaceholder 的 variable_name 一致\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"user_123\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59cbdd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = conversational_chain.invoke(\n",
    "    {\"input\": \"提示词工程是什么？\"},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcb2b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词工程（Prompt Engineering）是一种专注于如何编写和设计输入指令（Prompt）的技术，用于指导生成式人工智能模型执行特定任务。这些指令通常以自然语言文本形式出现，核心目的是清晰地描述模型应执行的任务，以引导模型生成特定的文本、图像、音频等内容。\n",
      "\n",
      "传统的自然语言处理研究遵循“预训练-微调-预测”范式，而提示词工程则属于“预训练-提示预测”新范式的一部分。在这种新范式下，通过精心设计的Prompt，预训练模型可以直接适应下游任务，无需繁琐的微调过程。Prompt的设计对模型性能有深远影响，是自然语言处理领域中的重要技术。\n"
     ]
    }
   ],
   "source": [
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feae835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词工程（Prompt Engineering）涉及多种技巧，以优化生成式人工智能模型的输出。以下是一些常见的技巧：\n",
      "\n",
      "### 1. **明确任务指令**\n",
      "- **具体化**：明确指出模型需要完成的任务，避免模糊不清的描述。\n",
      "- **示例引导**：提供具体的示例，帮助模型理解期望的输出格式。\n",
      "\n",
      "### 2. **上下文提供**\n",
      "- **背景信息**：提供相关的背景信息，帮助模型更好地理解任务。\n",
      "- **相关数据**：包含相关的数据或事实，增强模型的生成依据。\n",
      "\n",
      "### 3. **格式规范**\n",
      "- **结构化提示**：使用结构化的格式，如列表、表格等，使提示更易理解。\n",
      "- **模板化**：设计标准化的模板，确保输出的一致性。\n",
      "\n",
      "### 4. **逐步引导**\n",
      "- **分步提示**：将复杂任务分解为多个步骤，逐步引导模型。\n",
      "- **中间步骤**：提供中间步骤的示例，帮助模型逐步逼近最终目标。\n",
      "\n",
      "### 5. **多样化表达**\n",
      "- **同义词使用**：使用不同的词汇表达相同的意思，增加模型的灵活性。\n",
      "- **多角度描述**：从不同角度描述任务，丰富模型的输入信息。\n",
      "\n",
      "### 6. **情感与语气**\n",
      "- **情感引导**：根据任务需求，调整提示中的情感倾向。\n",
      "- **语气调整**：使用适当的语气，如正式、幽默等，以符合输出风格。\n",
      "\n",
      "### 7. **长度控制**\n",
      "- **简洁性**：尽量保持提示简洁，避免冗长信息干扰。\n",
      "- **信息量平衡**：确保提示包含足够的信息，但不过度冗余。\n",
      "\n",
      "### 8. **反馈与迭代**\n",
      "- **结果反馈**：根据模型的输出，调整和优化提示。\n",
      "- **迭代优化**：多次迭代，逐步改进提示的效果。\n",
      "\n",
      "### 9. **避免歧义**\n",
      "- **清晰表达**：避免使用容易引起歧义的词汇或表达。\n",
      "- **明确指代**：确保提示中的指代关系明确，避免混淆。\n",
      "\n",
      "### 10. **利用先验知识**\n",
      "- **领域知识**：结合特定领域的知识，提升模型的专业性。\n",
      "- **常识引入**：引入常识性信息，帮助模型做出更合理的推断。\n",
      "\n",
      "通过综合运用这些技巧，可以有效提升生成式模型的输出质量和任务适应性。\n"
     ]
    }
   ],
   "source": [
    "response1 = conversational_chain.invoke(\n",
    "    {\"input\": \"它有哪些技巧\"},\n",
    "    config=config\n",
    ")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519e149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
